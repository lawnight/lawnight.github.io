---
title: pandas
categories: python
---

对表格类数据的处理。pandas提供了两个重要的数据结构，Series和DataFrame，相当于1维数组，和表格。

# DataFrame

## 构建

- 等长列表的字典

```python
# 以a,b为列 创建DataFrame
m = {'a':[1,2,3],'b':[2,3,4]}
p = pd.DataFrame(m)
# 以a,b为index 创建DataFrame
pd.DataFrame.from_dict(result,orient='index')
```
- 嵌套字典

```python
#外侧key 为列
m = {'a':{'1':2},'b':{'1':2}}
pd.DataFrame(m)
```

- excel中读取
```python
# 读取excel的当前sheet页
d = pd.read_excel(r"D:\code\br_mix_server\excel\common\ConfigValue.xlsx",sheet_name='任务',skiprows=5)
# 读取所有sheet页
c = pd.concat(pd.read_excel(r'D:\code\br_mix_server\excel\common\ConfigValue.xlsx',sheet_name=None))

# 得到excel所有的sheet names
d = pd.ExcelFile(r"D:\code\br_mix_server\excel\common\ConfigValue.xlsx")
d.sheet_names
```

## 基本操作

```python
# 列的重命名
x.columns=['date','name','address','area','prices']
# 遍历row
for index,row in df.iterrows():
    print(row['c1'], row['c2']) # 输出每一行
```

## 筛选表格

iloc , 基于index的整数索引。
```python
# --------------- 对行的过滤
# 单行
df.iloc[0]
# 前两行
df[:2]
# 对行，列切片  iloc是int loc是str
df.iloc[0:1,1:2]
df.loc[:, 'max_speed'] = 30
# --------------- 对列的过滤
d[['B','C']]
d.B
```

生成布尔数组，并且根据bool数组来选择
```python
# isin bb是id列表
data['副本ID'].isin(bb)


# 通过bool数组来选择row ，传入二维数组的话，Flase的会变为None
section[(section['话分类']=='PLAY') & (section['本话名称(地图显示）'] == sId)]
d[d['A']>10]
```

## 汇总和数据统计

Series针对数字的列表提供很多统计方法，包括`sum`,`mean`,`std`,`count`等。也有`describe`等复合统计。DataFrame基本也有这些方法，而且可以选择对index，还是对columns操作。

聚合对Series指定多个统计方法
d2.agg(['min','count'])

## map

```python
>>> s.apply(lambda x: x ** 2)
London      400
New York    441
Helsinki    144
dtype: int64

s.map('I am a {}'.format, na_action='ignore')
```


map和apply 有部分重叠，建议用apply。



## 处理表格数据

### apply

DataFrame 的`apply`是对列或行进行操作，`applymap`是对每个元素操作

`apply`方法，可以对Seria和DataFrame使用
```python

# 对name列进行处理，把处理结果新加一列
d2['code'] = d2['name'].apply(lambda x: int(''.join(filter(str.isdigit, x))))
```

### 字符操作

对Series有大量的字符操作

```python
# 将字符按'|'分割成多列
x = x.str.split(pat='|',expand=True)
x.str.contans('x')
```

### drop

-   去掉指定name的行和列
-   也有dropna，和drop_duplicate等，根据内容drop行

```python
# 删除项目  axis 1:columns 0:index
d2.drop(['key'],axis = 1)
d2.drop(columns = ['B','C'])
d2.dropna()
# row的内容一样会被删除
d2.drop_duplicates(Keep=False)
# 
c = c.replace('',np.nan)
c = c.dropna()

# 列的类型转换
data[c1] = pd.to_numeric(data[c1].str[0:-1])
```

    
## 合并表

可以整合数据，也可以对比两个数据的差异。DataFrame，Series都可以
```python
# how 有三种模式，默认是inner，合并都有的key。left模式 没有一样key的时候保留左边表的记录,indicator 标记合并的key是否一边缺少
c = pd.merge(d,d2,on='key',how='left')
x = pd.merge(t1,t,left_on='剧本',right_on='所属小节(话)ID',how='right'，indicator = True)

# 列一样，合并index
pd.concat([df1,df2])
# 比较两个表的差异 ，本身row没有重复的
pd.concat([df1,df2]).drop_duplicates(keep=False)

```

## groupby


```python
grouped = df.groupby([8,12])
grouped.size().unstack(fill_value=0).to_csv('dd.csv')
```
grouped是一个GroupBy对象。实际上还没有进行任何计算，只是含有一些有关分组键的中间信息

### 对分组进行迭代

```python
# key为分组key，group为等于key的分组
for key,group in grouped:
    print(key)
    print(group)
```
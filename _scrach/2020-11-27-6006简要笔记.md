---
title: MIT6.006算法导论简要笔记
categories: others
---
MIT：https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/lecture-notes/

## unit1:介绍
峰值查找和python某些操作的时间复杂度。
## unit2:排序和Tree （5讲）

介绍了插入排序，并归排序，堆排序

### leture3. 插入和并归排序

插入排序比较简单，不用额外的空间，复杂度为O（n^2）。
Divide & Conquer的应用。 这个算法通常应用在内存比较小的地方。

merge sort 有两个要点

- 双指针算法合并有序集合，需要额外的辅助空间
- 递归树来证明时间复杂度

用recursion tree可以比较直观的证明merge sort的时间复杂度：
![](/assets/algo1.png)

### leture4. 堆排序

堆排序主要依赖于堆这种数据结构。产生堆的主要动机是需要一个优先队列。堆是一种用数组表示的完全二叉树。最大堆，代表任意node的值都大于它的children。最小堆反之。

堆排序只是堆的额外产物。最主要的应用还是堆的数据结构
***最大堆:***
![](/assets/algo.png)

用数组表示一个安全二叉树的时候，如果root的下标是1。
那么任意index为n的节点，子节点的下标为：
left(n) = 2n
right(n) = 2n+1

必须用数组吗？
如果不用数组，当我插入新节点的时候，不知道应该往哪里插入，而数组，就是直接追加到后面）

#### 构建堆

```python
def Build_Max_Heap(A):
    for i in range(n/2,1,-1):
        Max_heapify(A,i)
```

`Max-heapify(A,i)` 使A［i］满足最大堆的性质。从A节点依次往下比较，时间复杂度O(lgn)
对A［1…n／2］ 的非叶节点执行Max-heapify。最大堆就建立完毕。A[n/2+1….n] 都是leave节点。

**构建最大堆Build_Max_Heap的时间复杂度为O（n）。需要比较复杂的证明：**

- max_heapify一个节点需要O(lgn)。但是倒数一层的节点，只需要一次移动，也就是需要常量时间。
- 最下层有n/4 个node，倒数第二有n/8个node …..

所以可以得到公式：
`n/4 (1 c) + n/8 (2 c) + n/16 (3 c) + ... + 1 (lgn c)`
set  n/4 = 2k，化简方程。

#### 取最值

交换A[1]和A[n]，返回A[n]，再maxheapify(A,1)

#### 插入值

添加在数组末尾，再对其parent 进行max_heapify

```python
self.queue.append(key)
i = len(self)
while i>1:
    parent = i//2
    self.maxheapify(parent)
    i = parent
```

#### 堆排序

先构建最大堆。然后提出最大值，提出最大值的复杂度O（lgn）。所以排序的复杂度O（nlgn）

### leture5 & 6. 平衡二叉搜索树

#### 为什么需要二叉搜索树。

做到集合的**动态有序**，既可以二分查找，也可以O（lgn）的插入。
有序的数组，可以二分查找。但是插入操作需要消耗O（n）的时间。有序的链表可以很好的插入，但不能二分查找。

#### 平衡二叉树，AVL

除了AVL，还有很多平衡二叉树的现实：B树，红黑树，splay trees，skip lists等。

扩展数据结构，存储节点的高度,通过旋转的操作，保证每个节点的左右的高度相差1.就可以得到平衡二叉树。(二叉树节点的height，就是从节点到叶子节点的最长路径。)

在插入的时候，除了正常的二叉搜索树的插入，还要从下至上，用rotation来修复不满足AVL的属性的节点。

**保持高度相差1**
![](/assets/algo3.png)

**旋转:**
![](/assets/algo4.png)

### 7. 线性排序

#### 基于比较排序的下界
基于比较的排序算法比如： insertion sort,merge sort,quick sort,heap sort。
目前worst-case O(nlgn)。 是我们能得到的最好结果吗。用决策树可以比较方便的证明。

##### decision trees（决策树）

比如 对n=3的数组做二分查找的决策树：

叶子节点，应该包含所有的答案，对于x，应该有n+1种可能。所以，叶子节点是N+1，决策树又是一个二分树。所以树高至少是lgn。

对于排序的时间下界的证明会更复杂一点。排序的叶子节点应该有n!种可能。通过比较复杂的数学证明可以证明nlgn是比较排序方法，所能得到的最好下界。（具体见6.006 leture 7）

##### 线性时间排序

当对整数排序，并且数字不是很大的时候，可以很简单的达到线性时间的排序。
ifk=nO(1), can sort inO(n) time

##### counting sort（计数排序）

和hash很像，用k大小的数组来充当counter，用key来对应的数组index，来记录key。数字大小必须很小，数字越大对空间要求越大。因为需要大量空间，所以在实践中，速度并不是很快。而且没有局部性。
O(N+K)

##### Radix sort（基数排序）

按位排序，将数字当做底为b的数字形式（lgn位当作一个digit（数字） 

从低位到高位，对每个位数进行counting sort。

时间复杂度为：
Θ((n+b)d) = Θ((n+b) logbk) ，当b=n的时候可以得到最小值
Θ(nlognk）==》O(nc) if k≤n**c

虽然时间复杂度是O(n)，但是实践中，常数项c可能比较大，而且局部性没有快排好。所以实际运用中，快排比radix sort更快。

#####  桶排序（bocket socket） 视频没有讲

和计数排序其实很像。

计数排序基于：数都分布在很小的区间
桶排序基于：树都均匀分布在一个区间


目前最好的排序算法：O（nrootlg(lgn)） 很复杂。高级算法课有讲，
最坏情况：O（nlg(lgn)） 高级算法课有讲。

## Unit 3: Hashing

这部分自己比较熟悉，也有较多笔记，就暂时先不整理

## unit 4：大数乘法和除法 Numerics
### leture11. karatsuba 乘法
分治法。将数按照高低位分为两部分，直到降低到cpu可以处理的位数，比如64位。这样时间复杂度为**theta(n^2)**
![](/assets/algo7.png)




#### karatsuba's method

![5](/assets/algo8.png)

将4次乘法减少为3次乘法，递归式变为：`T(n)=3T(n/2)+theta(n)`，随意时间复杂度为theta(n^lg3)。但时间复杂度有更高的常数项。在RSA中就不适用。

### leture12. 除法和开平方根

**Newton's Methon：**

![5](/assets/algo5.png)

f(x)的导数 就是切线的斜率。所以可以构造出切线的方程为`y=f(xi)+f'(xi)(x-xi)`。就可以推导出递归方程：
![6](/assets/algo6.png)
每次递归可以让精度d，d = d^2。

#### 用牛顿方法计算除法

构造f(x)，使f(x)=0时，x就是要求的除法。但是最后还是有除法。所以关键在选择一个容易被除的R，比如2的次方。可以用位移来计算R的除法。
![](/assets/algo9.png)

## unit5:图

邻接列表表示图

### leture13. 广度遍历 breadth-first search(BFS)

- 层序遍历
- 最短路径（最少的边）

### leture14. 深度遍历 Depth-first search (DFS)
	
- 二叉树的前中后序就是深度遍历
- 深度遍历就像寻找迷宫的出口。（也就是国内教程常说的回溯法）

```python
parent = {s: None}
#从s点开始遍历
def DFS-visit (Adj, s):
	# s相邻的点
	 for v in Adj [s]:
		# start v
		 if v not in parent:
		     parent [v] = s
		     DFS-visit (Adj, v)
		 # finish v            （经常需要添加逻辑的地方，回溯的地方，比如路径remove ，v）

#每个顶点遍历，避免图不连通的地方
def DFS (V, Adj)
	 parent = { }
	 for s in V:
		 if s not in parent:
		 parent [s] = None
		 DFS-visit (V, Adj, s)
```


#### 边的类型
深度遍历可以区分边的类型。通过判断是否有back edge，来确定图是否有环。当DFS(V,Adj)时，parent不为空，就代表有back dege。

#### 拓扑排序 

reverse of DFS finishing times。就是图的拓扑排序。


## unit 6:单源最短路径（4讲）

单源最短路径就是在一个图中，寻找到S,V之间的最短距离S(s,v)。

两个算法
- Dijkstra 
    ○ 贪心算法
    ○ 只能处理没有 negative edge的情况。
- Bellman Ford
    ○ 更为通用，有negative dege，并且有cycle，都可以处理。复杂度为O(VE)

#### Relaxtion

relax edge是一个基本操作，不同的算法，只是区分如何选取edge，然后应用Relaxtion。

d[v]为源s点到v最短路径的长度。

```python
def RELAX(u; v; w)
	if d[v] > d[u] + w(u; v)
		d[v] = d[u] + w(u; v)
		Π[v] = u
```


具体实现

#### 1. dijkstra

```python
Dijkstra (G; W; s)            //uses priority queue Q
	Initialize (G; s)
	S <- φ
	Q <- V [G] //Insert into Q
	while Q = φ:
		do u = EXTRACT-MIN(Q)      //deletes u from Q
		S = S .add(u)
		for each vertex v in Adj[u]
			do RELAX (u; v; w)    //this is an implicit DECREASE KEY operation
```

**每次从优先队列中，取出d[v]最小的vertex（贪心）**。选用不同的数据结构实现优先队列会有不同的复杂度。
最优选用Fibonacci heap有O（VlgV+E）的复杂度。

#### 2. Bellman Ford

**对于想要找到的不包括循环的最短路径，路径经过的顶点数应该不超过V - 1**。假设路径为：S，v0，v1，v2。。。v。   第一次循环pass，能找到v0，第二次能知道v1，依次类推。
```python
def Bellman-Ford(G,W,s):
	Initialize ()
	for i = 1 to |V| − 1
		for each edge (u; v) 2 E:
			Relax(u; v)
	for each edge (u; v) 2 E
		do if d[v] > d[u] + w(u; v)
			then report a negative-weight cycle exists
```

## unit7:动态规划 （4讲）

用动态规范的思路，实现了单源最短路径的Dijkstra和Bellman Ford算法。

### 解题步骤
	1. 定义子问题。
	2. guess （part of solution）
	3. 递归方程。
	4. 分析子问题的topological sort。从下到上构建for循环
	5. 需要求解问题的形式

### 子问题

如何定义子问题是最难的一步。通常第一步和第二步是一起考虑的。思考怎么遍历所有的可能解，怎么来猜第一步， 来拆解问题。（what to guess ，what subproblem）
比如
矩阵连乘，guess最后一步的乘法是哪两个序列。然后看最后一步乘法，可以选择的范围。

对于问题是序列的形势。比如字符串，图的线性排序。可以有三种拆分子问题的形式：

- 前缀 （text 自动分行）
- 后缀
- 子序列

一般会先尝试用后缀。

两种guess的方法：

- guess which other subproblems to use
- create more subproblems to guess or remember more structure of solution （背包问题）

### 例题

剑指 Offer 48. 最长不含重复字符的子字符串
	- 定义子问题，用到了特殊意义的前缀，使之还是包括最优解，最后求所有子问题的max
		○ dp[j] 代表以字符 s[j] 为结尾的 “最长不重复子字符串” 的长度
		○ max(dp[j])
6.006 作业7
	- 股票问题：用更多的选择或者更多的问题
123. 买卖股票的最佳时机 III
	- 用了三维数组保存状态 dp[][][]。